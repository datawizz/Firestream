### Fireworks ###
PROJECT_NAME="fireworks"

# Set the Machine ID on Debian host
MACHINE_ID="unknown"

### Deployment ###
DEPLOYMENT_MODE=''

### Github ###
GITHUB_SSH_KEY='' # Used for pulling private registries
GIT_COMMIT_HASH='development' # Filled in later using the actual commit hash. Used for image tags

### Docker ###
DOCKER_BUILDKIT=1
CONTAINER_REGISTRY_URL_FULL='k3d-fireworks.localhost:5055'
CONTAINER_REGISTRY_URL='localhost'
CONTAINER_REGISTRY_PORT=5055
FEATURE_FLAG_DOCKER=1
FEATURE_FLAG_DOCKER_REGISTRY=1


### Framework Versions ###
# For packages which are built from source, we need to specify the version number and hash
SPARK_VERSION=3.3.2
SPARK_SHA512="347fd9029128b12e7b05e9cd7948a5b571a57f16bbbbffc8ad4023b4edc0e127cffd27d66fcdbf5f926fa33362a2ae4fc0a8d59ab3abdaa1d4c4ef1e23126932  spark-3.3.2-bin-without-hadoop.tgz"
SPARK_HOME=/opt/spark
FEATURE_FLAG_SPARK=1

HADOOP_VERSION=3.3.4
HADOOP_SHA512="ca5e12625679ca95b8fd7bb7babc2a8dcb2605979b901df9ad137178718821097b67555115fafc6dbf6bb32b61864ccb6786dbc555e589694a22bf69147780b4  hadoop-3.3.4.tar.gz"
HADOOP_HOME=/opt/hadoop



### Kafka ###
KAFKA_BOOTSTRAP_SERVER="kafka.default.svc.cluster.local"
KAFKA_BOOTSTRAP_SERVER_PORT="9092"
KAFKA_BOOTSTRAP_SERVERS="kafka.default.svc.cluster.local:9092"
FEATURE_FLAG_KAFKA=1

### S3 ###
# Define two S3 buckets, one for "in-cluster" aka local
# and one for "out-of-cluster" aka cloud.

# For the "Local" deployment, we use a local minio instance
S3_LOCAL_ACCESS_KEY_ID='TODO_CHANGE_ME'
S3_LOCAL_SECRET_ACCESS_KEY='THIS_IS_A_SECRET_TODO_CHANGE_ME'
S3_LOCAL_DEFAULT_REGION='us-west-2'
S3_LOCAL_ENDPOINT_URL='http://minio.default.svc.cluster.local:9000'
S3_LOCAL_BUCKET_NAME='fireworks'
FEATURE_FLAG_S3_LOCAL_STORAGE=1

# For the "Cloud" deployment, we use a cloud S3 instance (or a local minio instance on another machine)
# It is assumed that this cloud instance is not deleted when the cluster is deleted
S3_CLOUD_ACCESS_KEY_ID='TODO_CHANGE_ME'
S3_CLOUD_SECRET_ACCESS_KEY='THIS_IS_A_SECRET_TODO_CHANGE_ME'
S3_CLOUD_DEFAULT_REGION='us-west-2'
S3_CLOUD_ENDPOINT_URL='https://my-bucket.s3.us-west-2.amazonaws.com'
S3_CLOUD_BUCKET_NAME='fireworks-cloud'
FEATURE_FLAG_S3_CLOUD_STORAGE=1


### Cloud Storage ###
# TODO make generic for any cloud storage
FEATURE_FLAG_CLOUD_STORAGE=0



### DataFlow ###
FEATURE_FLAG_DATAFLOW=1


# S3_ACCESS_KEY_ID='TODO_CHANGE_ME'
# S3_SECRET_ACCESS_KEY='THIS_IS_A_SECRET_TODO_CHANGE_ME'
# S3_DEFAULT_REGION='us-west-2'
# S3_ENDPOINT_URL='http://minio.default.svc.cluster.local:9000'
# S3_BUCKET_NAME='fireworks'

# LOCAL_DATA_DIR='/workspace/tmp/data'
### MinIO Local Staging Semi-Permanent ###
# S3_ACCESS_KEY_ID='UTMs2xbPYleLRdKs1sT7'
# S3_SECRET_ACCESS_KEY='TUiPgi2obcId2ev164xk'
# S3_ENDPOINT_URL='http://10.0.0.232:9000'
# S3_DEFAULT_REGION='us-west-2'
# S3_BUCKET_NAME='fireworks-staging'

## Spark ##
# SPARK_LOCAL_IP="127.0.1.1"

### PostgreSQL ###
POSTGRES_USER='pguser'
POSTGRES_PASSWORD='THIS_IS_A_SECRET_TODO_CHANGE_ME'
POSTGRES_DEFAULT_DB='postgres'
POSTGRES_URL="postgresql.default.svc.cluster.local"
POSTGRES_PORT=5432
JDBC_CONNECTION_STRING=jdbc:postgresql://postgresql.default.svc.cluster.local:5432/postgres
DATABASE_URL=postgres://pguser:THIS_IS_A_SECRET_TODO_CHANGE_ME@postgresql.default.svc.cluster.local:5432/postgres
#POSTGRES_CONNECTION_STRING=postgres://pguser:THIS_IS_A_SECRET_TODO_CHANGE_ME@postgresql.default.svc.cluster.local:5432/lakefs
FEATURE_FLAG_POSTGRES=1


### Superset ###
SUPERSET_DATABASE_URI=postgresql://pguser:THIS_IS_A_SECRET_TODO_CHANGE_ME@postgresql:5432/postgres
SUPERSET_URL=http://superset.default.svc.cluster.local:8088
# TODO make a database in Superset from helm

### Kyuubi ###
HIVE_THRIFT="kyuubi-thrift-binary.default.svc.cluster.local"
KYUUBI_HOME=/opt/kyuubi


### HADOOP ###
HADOOP_HOME=/opt/hadoop



### Open Search ###
OPENSEARCH_URL='https://opensearch-cluster-master.default.svc.cluster.local:9200'
OPENSEARCH_HOST="opensearch-cluster-master.default.svc.cluster.local"
OPENSEARCH_PORT="9200"
OPENSEARCH_USERNAME='admin'
OPENSEARCH_PASSWORD='admin'

### CUDA ###
CUDA_VERSION="12"
CUDA_HOME="/usr/local/cuda"
NVIDIA_DRIVER_VERSION="525.60.13"

### Supabase ###
# SITE_URL=http://192.0.2.0:3000
# API_EXTERNAL_URL=http://192.0.2.0:8000
# STUDIO_PORT=3000
# PUBLIC_REST_URL=http://192.0.2.0:8000/rest/v1/

# ### Customer Analytics ###
# REACT_APP_GOOGLE_ANALYTICS_GTAG='G-XXXXXXXXXX'
# REACT_APP_AMPLITUDE_ANALYTICS_API_KEY='XXXXXXXXX'
# REACT_APP_MIXPANEL_ANALYTICS_KEY='XXXXXXXXX'

# ### OPEN AI ###
# OPENAI_API_KEY='XXXXXXXXX'

# ### TODO parse this from Quadratic and condense
# REACT_APP_GOOGLE_ANALYTICS_GTAG=G-0000000000
# REACT_APP_AMPLITUDE_ANALYTICS_API_KEY=
# REACT_APP_MIXPANEL_ANALYTICS_KEY=
# REACT_APP_SENTRY_DSN=https://xxxxxxxxxxxxxxxxxx@xxxxxxxxxxxx.ingest.sentry.io/xxxxxxxxxxxx
# # // use =1 to enable debug flags
# REACT_APP_DEBUG=0 
# REACT_APP_AUTH0_DOMAIN=auth-dev.quadratic.to
# REACT_APP_AUTH0_CLIENT_ID=XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX
# REACT_APP_AUTH0_AUDIENCE=https://localhost:8000
# REACT_APP_AUTH0_ISSUER=https://auth-dev.quadratic.to/
# REACT_APP_QUADRATIC_API_URL=http://localhost:8000

### Rust ###
RUST_BACKTRACE=full


### Websocket Middleware ###
FEATURE_FLAG_WEBSOCKET_MIDDLEWARE=1



### NGROK ###
NGROK_DOMAIN="demo.fireworks.ngrok.dev"
# NGROK_DIR="$HOME/.ngrok"
NGROK_AUTHTOKEN="TODO_CHANGE_ME"
NGROK_API_KEY="TODO_CHANGE_ME"


### Domains ###
SUBDOMAIN_API="api.fireworks.ngrok.dev"
SUBDOMAIN_APP="app.fireworks.ngrok.dev"
SUBDOMAIN_ADMIN="admin.fireworks.ngrok.dev"

TLS_SECRET="tls-certificate"


### Protobuf Compiler ###
PROTOC=/usr/bin/protoc


### LakeFS ###
LAKEFS_BUCKET_NAME='fireworks'
LAKEFS_ACCESS_KEY='TODO_CHANGE_ME2'
LAKEFS_SECRET_KEY='THIS_IS_A_SECRET_TODO_CHANGE_ME2'
LAKEFS_DEFAULT_REGION='us-west-2'
LAKEFS_ENDPOINT_URL='http://lakefs.default.svc.cluster.local:80/api/v1'