################################################################################
# FIRESTREAM CONFIGURATION EXAMPLE
#
# This file contains all environment variables used by Firestream.
# Copy this file to .env and update with your actual values.
#
# NEVER commit your actual .env file to version control!
#
# IMPORTANT NOTES:
# - Variables marked as "Auto-set by pre-init script" should NOT be manually
#   configured - they are automatically detected by docker/scripts/pre-init.sh
# - Sensitive values (passwords, API keys) should go in etc/.env.secrets
# - The pre-init script must be run before starting containers
################################################################################

################################################################################
# 1. CORE CONFIGURATION
################################################################################

#===============================================================================
# PROJECT IDENTIFICATION
#===============================================================================
# NOTE: This project uses a two-file configuration approach:
# 1. This .env file for general configuration
# 2. A separate .env.secrets file for sensitive values
#
# The pre-init script looks for secrets in the etc/ directory:
# - etc/.env.secrets (production - create this from the example)
# - etc/.env.secrets.example (fallback for development)
#
# Keep passwords, API keys, and other sensitive values in .env.secrets

# Project identifier used across the system
PROJECT_NAME="firestream"

# Docker Compose project name (required for VSCode remote development)
COMPOSE_PROJECT_NAME="firestream"

# Deployment mode: development | staging | production
DEPLOYMENT_MODE="development"

# Environment type for various configurations
ENVIRONMENT="development"

# Unique deployment identifier
DEPLOYMENT_NAME="my-deployment"

# Customer information (for multi-tenant deployments)
CUSTOMER_NAME="CUSTOMER_NAME_HERE"
CUSTOMER_EMAIL_DOMAIN="customer.com"

# Machine prefix for naming conventions
MACHINE_PREFIX="devbox"

# Region identifier
REGION="us1"

# Data rotation policy (days)
ROTATION_DAYS=30

#===============================================================================
# VERSION CONTROL
#===============================================================================

# GitHub SSH key for pulling private repositories (base64 encoded)
GITHUB_SSH_KEY=""

# Git commit hash used for Docker image tagging (auto-populated in CI/CD)
GIT_COMMIT_HASH="development"

################################################################################
# 2. INFRASTRUCTURE & RUNTIME
################################################################################

#===============================================================================
# CONTAINER CONFIGURATION
#===============================================================================
# NOTE: The pre-init script passes host configuration as both environment
# variables and Docker build arguments to ensure proper container setup

# Docker build configuration
DOCKER_BUILDKIT=1

# Container registry settings
CONTAINER_REGISTRY_URL_FULL="k3d-firestream.localhost:5055"
CONTAINER_REGISTRY_URL="localhost"
CONTAINER_REGISTRY_PORT=5055

# Feature flags for Docker functionality
FEATURE_FLAG_DOCKER=1
FEATURE_FLAG_DOCKER_REGISTRY=1

#===============================================================================
# HOST SYSTEM
#===============================================================================
# IMPORTANT: The following HOST_* variables are automatically set by the
# pre-init script (docker/scripts/pre-init.sh) and should NOT be manually
# configured unless you're bypassing the standard initialization process.
#
# The pre-init script supports both Linux and macOS and detects:
# - HOST_USER_ID (defaults to 1000)
# - HOST_GROUP_ID (defaults to 1000)
# - HOST_USERNAME (defaults to "firestream")
# - HOST_DOCKER_GID (from docker group - Linux only)
# - HOST_MACHINE_ID (from system)
# - HOST_IP (from network interfaces)
# - HOST_GPU_STATUS (based on GPU detection)
# - HOST_GPU_VENDOR (NVIDIA on Linux, Apple Metal on macOS, or Other)
# - HOST_KVM_STATUS (Linux KVM virtualization support)

# Host user and group IDs for volume permissions
# HOST_USER_ID=""          # Auto-set by pre-init script
# HOST_GROUP_ID=""         # Auto-set by pre-init script

# OCI engine: docker | podman
HOST_OCI_ENGINE="docker"

# Docker group ID on host system
# HOST_DOCKER_GID=""       # Auto-set by pre-init script

# Host machine identification
# HOST_MACHINE_ID=""       # Auto-set by pre-init script

# Host IP address
# HOST_IP=""               # Auto-set by pre-init script

# GPU availability and vendor
# HOST_GPU_STATUS=false    # Auto-set by pre-init script
# HOST_GPU_VENDOR=""       # Auto-set by pre-init script

# KVM virtualization support (Linux only)
# HOST_KVM_STATUS=false    # Auto-set by pre-init script

#===============================================================================
# GPU SUPPORT
#===============================================================================
# NOTE: GPU detection (HOST_GPU_STATUS and HOST_GPU_VENDOR) is handled
# automatically by the pre-init script. The script detects:
# - NVIDIA GPUs on Linux
# - Apple Metal on macOS
# - Sets HOST_GPU_STATUS=true if compatible GPU found

# NVIDIA CUDA configuration (only used if NVIDIA GPU detected)
CUDA_VERSION="12"
CUDA_HOME="/usr/local/cuda"
NVIDIA_DRIVER_VERSION="525.60.13"

#===============================================================================
# NETWORKING
#===============================================================================

# TLS certificate configuration
TLS_SECRET="tls-certificate"
VERIFY_SSL_CERTS="false"

# Public domain configuration
PUBLIC_DOMAIN="example.com"

################################################################################
# 3. DATA PLATFORM CORE
################################################################################

#===============================================================================
# BIG DATA PROCESSING
#===============================================================================

# Apache Spark configuration
SPARK_HOME=/opt/spark
FEATURE_FLAG_SPARK=1

# Apache Hadoop configuration
HADOOP_HOME=/opt/hadoop

#===============================================================================
# MESSAGE STREAMING
#===============================================================================

# Kafka cluster configuration
KAFKA_BOOTSTRAP_SERVER="kafka.default.svc.cluster.local"
KAFKA_BOOTSTRAP_SERVER_PORT="9092"
KAFKA_BOOTSTRAP_SERVERS="kafka.default.svc.cluster.local:9092"
FEATURE_FLAG_KAFKA=1

#===============================================================================
# OBJECT STORAGE
#===============================================================================

# Feature flag for cloud storage functionality
FEATURE_FLAG_CLOUD_STORAGE=1
FEATURE_FLAG_DATAFLOW=1

#-------------------------------------------------------------------------------
# LOCAL STORAGE (MinIO) - For development/testing
#-------------------------------------------------------------------------------

# Local S3 storage configuration (typically MinIO)
S3_LOCAL_ACCESS_KEY_ID="CHANGE_ME_LOCAL_ACCESS_KEY"
S3_LOCAL_SECRET_ACCESS_KEY="CHANGE_ME_LOCAL_SECRET_KEY"
S3_LOCAL_DEFAULT_REGION="us-west-2"
S3_LOCAL_ENDPOINT_URL="http://minio.default.svc.cluster.local:9000"
S3_LOCAL_BUCKET_NAME="firestream"
FEATURE_FLAG_S3_LOCAL_STORAGE=1

#-------------------------------------------------------------------------------
# CLOUD STORAGE - For production/external storage
#-------------------------------------------------------------------------------

# Cloud S3 storage configuration (AWS S3 or compatible)
S3_CLOUD_ACCESS_KEY_ID="CHANGE_ME_CLOUD_ACCESS_KEY"
S3_CLOUD_SECRET_ACCESS_KEY="CHANGE_ME_CLOUD_SECRET_KEY"
S3_CLOUD_DEFAULT_REGION="us-west-2"
S3_CLOUD_BUCKET_NAME="firestream-prod"
FEATURE_FLAG_S3_CLOUD_STORAGE=1

################################################################################
# 4. DATA MANAGEMENT & DATABASES
################################################################################

#===============================================================================
# PRIMARY DATABASE - POSTGRESQL
#===============================================================================

# PostgreSQL primary configuration
POSTGRES_USER="pguser"
POSTGRES_PASSWORD="CHANGE_ME_SECURE_PASSWORD"
POSTGRES_DB="firestream"
POSTGRES_DEFAULT_DB="firestream"
POSTGRES_URL="postgresql.default.svc.cluster.local"
POSTGRES_PORT=5432

# Database connection strings (various formats for different services)
JDBC_CONNECTION_STRING="jdbc:postgresql://postgresql.default.svc.cluster.local:5432/firestream"


# Used by the Firestream API Server, which server the Model Context Protocol (MCP)
# This assume it is runniung in the container.
DATABASE_URL="postgres://pguser:CHANGE_ME_SECURE_PASSWORD@host.docker.internal:5432/firestream"

# Feature flag for PostgreSQL
FEATURE_FLAG_POSTGRES=1

# PostgreSQL environment variables for CLI tools
PGHOST="localhost"
PGPORT="5432"
PGUSER="pguser"
PGDATABASE="firestream"
PGPASSWORD="CHANGE_ME_SECURE_PASSWORD"

#===============================================================================
# DATA CATALOG & METADATA
#===============================================================================

# Hive Metastore configuration
METASTORE_HOME=/opt/hive-metastore
METASTORE_DB_NAME=hive_metastore
METASTORE_URL="hive-metastore.default.svc.cluster.local"
METASTORE_PORT=9083

# Nessie server configuration for data versioning
NESSIE_SERVER_URI="http://nessie.default.svc.cluster.local:19120/api/v1"
NESSIE_VERSION="0.70.0"

#===============================================================================
# DATA VERSIONING
#===============================================================================

# LakeFS configuration for data versioning
LAKEFS_BUCKET_NAME="firestream"
LAKEFS_ACCESS_KEY="CHANGE_ME_LAKEFS_ACCESS_KEY"
LAKEFS_SECRET_KEY="CHANGE_ME_LAKEFS_SECRET_KEY"
LAKEFS_DEFAULT_REGION="us-west-2"
LAKEFS_ENDPOINT_URL="http://lakefs.default.svc.cluster.local:80/api/v1"

#===============================================================================
# SQL GATEWAY
#===============================================================================

# Kyuubi Thrift server configuration
HIVE_THRIFT="kyuubi-thrift-binary.default.svc.cluster.local"
KYUUBI_HOME=/opt/kyuubi

################################################################################
# 5. ANALYTICS & BUSINESS INTELLIGENCE
################################################################################

#===============================================================================
# SEARCH & ANALYTICS ENGINE
#===============================================================================

# OpenSearch cluster configuration
OPENSEARCH_URL="https://opensearch-cluster-master.default.svc.cluster.local:9200"
OPENSEARCH_HOST="opensearch-cluster-master.default.svc.cluster.local"
OPENSEARCH_PORT="9200"
OPENSEARCH_USERNAME="admin"
OPENSEARCH_PASSWORD="CHANGE_ME_OPENSEARCH_PASSWORD"

#===============================================================================
# DATA VISUALIZATION
#===============================================================================

# Apache Superset configuration
SUPERSET_DATABASE_URI="postgresql://pguser:CHANGE_ME_SECURE_PASSWORD@postgresql:5432/firestream"
SUPERSET_URL="http://superset.default.svc.cluster.local:8088"

#===============================================================================
# DATA TRANSFORMATION
#===============================================================================

# DBT profiles directory
DBT_PROFILES_DIR=~/.dbt

################################################################################
# 6. ORCHESTRATION & OPERATIONS
################################################################################

#===============================================================================
# WORKFLOW ORCHESTRATION
#===============================================================================

# Airflow base configuration
AIRFLOW_HOME=/workspace/tmp/airflow
AIRFLOW_URL="airflow.default.svc.cluster.local"
AIRFLOW_PORT=8080

# Airflow database connection
AIRFLOW__DATABASE__SQL_ALCHEMY_CONN="postgresql://pguser:CHANGE_ME_SECURE_PASSWORD@postgresql.default.svc.cluster.local:5432/firestream"

# Airflow directory paths
AIRFLOW_DAGS_FOLDER=/workspace/out/airflow/dags
AIRFLOW_PLUGINS_FOLDER=/workspace/out/airflow/plugins
AIRFLOW_LOGS_FOLDER=/workspace/out/airflow/logs

# Airflow connections
AIRFLOW_CONN_POSTGRES_DEFAULT="postgresql://pguser:CHANGE_ME_SECURE_PASSWORD@postgresql.default.svc.cluster.local:5432/firestream"

#===============================================================================
# OBSERVABILITY & MONITORING
#===============================================================================

# Jaeger tracing configuration
JAEGER_URL="http://jaeger-agent.default.svc.cluster.local:16686"
OTEL_EXPORTER_JAEGER_AGENT_HOST="jaeger-agent.default.svc.cluster.local"
OTEL_EXPORTER_JAEGER_AGENT_PORT="6831"

################################################################################
# 7. CLOUD SERVICES & INTEGRATIONS
################################################################################

#===============================================================================
# GOOGLE CLOUD PLATFORM
#===============================================================================

# Google Cloud Platform settings
GCP_PROJECT="your-gcp-project"
GCP_REGION="us-central1"
GCP_REGION_ZONE="us-central1-a"
# 3 CPU 16 GB RAM ~ 100/mo
GCE_MACHINE_TYPE="e2-standard-2"

#===============================================================================
# CLOUDFLARE
#===============================================================================

# Cloudflare Tunnels are used to make the applications accessible from the internet

# Cloudflare API configuration
CLOUDFLARE_API_TOKEN="YOUR_CLOUDFLARE_API_TOKEN"
CLOUDFLARE_ZONE_ID="YOUR_CLOUDFLARE_ZONE_ID"
CLOUDFLARE_ACCOUNT_ID="YOUR_CLOUDFLARE_ACCOUNT_ID"
CLOUDFLARE_DOMAIN="your-domain.com"
CLOUDFLARE_PUBLIC_DOMAIN="your-public-domain.com"

#===============================================================================
# TAILSCALE VPN
#===============================================================================

# Tailscale VPN configuration
TAILSCALE_API_KEY="YOUR_TAILSCALE_API_KEY"
TAILSCALE_TAILNET_NAME="your-tailnet"

################################################################################
# 8. APPLICATION CONFIGURATION
################################################################################

#===============================================================================
# FIRESTREAM API SERVER
#===============================================================================

# API server network configuration
APP_SERVER__IP="0.0.0.0"
APP_SERVER__PORT=3000

# Application database URL (used by the API server)
APP_DATABASE__URL="postgresql://pguser:CHANGE_ME_SECURE_PASSWORD@localhost:5432/firestream"

# SQLx offline mode (set to 1 to use cached query metadata)
SQLX_OFFLINE=0

################################################################################
# 9. DEVELOPMENT & DEBUGGING
################################################################################

#===============================================================================
# DEVELOPMENT TOOLS
#===============================================================================

# Rust debugging
RUST_BACKTRACE=full

################################################################################
# END OF CONFIGURATION
#
# Checklist before deploying:
# ✓ Run the pre-init script (docker/scripts/pre-init.sh) to auto-detect host settings
# ✓ Replace all CHANGE_ME_* values with secure passwords
# ✓ Update service URLs if not using default Kubernetes namespaces
# ✓ Configure cloud provider settings if deploying to cloud
# ✓ Set appropriate feature flags for your deployment
# ✓ Verify storage endpoints and credentials
# ✓ Ensure all ports are correctly configured for your network
#
# The pre-init script automatically:
# - Detects host system configuration (user/group IDs, machine ID, IP)
# - Identifies GPU capabilities (NVIDIA on Linux, Apple Metal on macOS)
# - Checks KVM virtualization support (Linux only)
# - Sets Docker group permissions
# - Generates docker-compose.devcontainer.yml with appropriate configurations
# - Applies GPU-specific overrides when NVIDIA GPU is detected
################################################################################
